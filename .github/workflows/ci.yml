name: ci

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: "1 1 * * 1"

permissions:
  contents: write
  deployments: write

jobs:
  bench-go:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        go-version: ["1.20"]

    steps:
      - uses: actions/checkout@v3

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: ${{ matrix.go-version }}

      - name: Build
        run: make setup

      - name: Test
        run: |
          make test | grep "ops over" | tee benchmark_lotsa_result.txt

      - name: Bench
        run: |
          make bench | tee benchmark_result.txt

      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.18.0
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          name: Go Library Benchmark
          tool: "go"
          output-file-path: benchmark_result.txt
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/ringsaturn/tz-benchmark"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: false
          fail-on-alert: false
          gh-pages-branch: "gh-pages"
          benchmark-data-dir-path: "docs/"
          alert-comment-cc-users: "@ringsaturn"

      - name: Setup benchmark file name
        id: gen-benchmark-file-name
        run: |
          echo "filename=tz_benchmark_go_${{ matrix.go-version }}.md" >> $GITHUB_OUTPUT

      - name: Report
        run: |
          set +e
          echo "## Go ${{ matrix.go-version }}" >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          cat benchmark_result.txt >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}

      - name: Upload artifact
        uses: actions/upload-artifact@v3
        with:
          name: "benchmark_result_as_md"
          path: ${{ steps.gen-benchmark-file-name.outputs.filename }}

  bench-python:
    runs-on: ubuntu-latest
    env:
      COLUMNS: 120
    strategy:
      matrix:
        python-version: ["3.11"]

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Build
        run: |
          pip install -r requirements.txt

      - name: Setup benchmark file name
        id: gen-benchmark-file-name
        run: |
          echo "filename=tz_benchmark_py_${{ matrix.python-version }}.md" >> $GITHUB_OUTPUT

      - name: Bench Python
        run: |
          # ${{ steps.gen-benchmark-file-name.outputs.filename }}
          pytest tz_test.py --benchmark-json output.json | tee benchmark_result.txt

      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.18.0
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          name: Python Library Benchmark
          tool: "pytest"
          output-file-path: output.json
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/ringsaturn/tz-benchmark"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: false
          fail-on-alert: false
          gh-pages-branch: "gh-pages"
          benchmark-data-dir-path: "docs/"
          alert-comment-cc-users: "@ringsaturn"

      - name: Report
        run: |
          set +e
          echo "## Python ${{ matrix.python-version }}" >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          cat benchmark_result.txt >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}

      - name: Upload artifact
        uses: actions/upload-artifact@v3
        with:
          name: "benchmark_result_as_md"
          path: ${{ steps.gen-benchmark-file-name.outputs.filename }}

  bench-rust:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Setup benchmark file name
        id: gen-benchmark-file-name
        run: |
          echo "filename=tz_benchmark_rust.md" >> $GITHUB_OUTPUT

      - run: cargo build --release

      - name: Run benchmark
        run: cargo bench | tee benchmark_result.txt

      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.18.0
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          name: Rust Library Benchmark
          tool: "cargo"
          output-file-path: benchmark_result.txt
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/ringsaturn/tz-benchmark"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: false
          fail-on-alert: false
          gh-pages-branch: "gh-pages"
          benchmark-data-dir-path: "docs/"
          alert-comment-cc-users: "@ringsaturn"

      - name: Report
        run: |
          set +e
          echo "## Rust" >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          cat benchmark_result.txt >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}

      - name: Upload artifact
        uses: actions/upload-artifact@v3
        with:
          name: "benchmark_result_as_md"
          path: ${{ steps.gen-benchmark-file-name.outputs.filename }}

  summary:
    needs: [bench-go, bench-python, bench-rust]
    runs-on: ubuntu-latest
    steps:
      - name: Download a Build Artifact
        uses: actions/download-artifact@v3
        with:
          name: "benchmark_result_as_md"
          path: ""

      - name: Make Summary
        run: cat tz_benchmark_*.md > $GITHUB_STEP_SUMMARY
