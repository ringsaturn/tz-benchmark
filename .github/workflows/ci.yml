name: ci

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: "1 1 * * 1"

permissions:
  contents: write
  deployments: write

jobs:
  bench-go:
    defaults:
      run:
        working-directory: go
    runs-on: ubuntu-latest
    strategy:
      matrix:
        go-version: ["1.21"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ matrix.go-version }}

      # - name: Test
      #   run: |
      #     go test -v ./... | grep "ops over" | tee benchmark_lotsa_result.txt

      - name: Bench
        run: |
          go test -bench=. -benchmem ./... | tee benchmark_result.txt

      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.19.2
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          name: Go Library Benchmark
          tool: "go"
          output-file-path: go/benchmark_result.txt
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/ringsaturn/tz-benchmark"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: false
          fail-on-alert: false
          gh-pages-branch: "gh-pages"
          benchmark-data-dir-path: "docs/"
          alert-comment-cc-users: "@ringsaturn"

      - name: Setup benchmark file name
        id: gen-benchmark-file-name
        run: |
          echo "filename=tz_benchmark_go_${{ matrix.go-version }}.md" >> $GITHUB_OUTPUT

      - name: Report
        run: |
          set +e
          echo "## Go ${{ matrix.go-version }}" >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          cat benchmark_result.txt >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}

      - run: ls -lah

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark_go_${{ steps.gen-benchmark-file-name.outputs.filename }}
          path: go/${{ steps.gen-benchmark-file-name.outputs.filename }}
          if-no-files-found: error

  bench-python:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: python
    env:
      COLUMNS: 120
    strategy:
      matrix:
        python-version: ["3.12"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Build
        run: |
          pip install -r requirements.txt

      - name: Setup benchmark file name
        id: gen-benchmark-file-name
        run: |
          echo "filename=tz_benchmark_py_${{ matrix.python-version }}.md" >> $GITHUB_OUTPUT

      - name: Bench Python
        run: |
          # ${{ steps.gen-benchmark-file-name.outputs.filename }}
          pytest tz_test.py --benchmark-json output.json | tee benchmark_result.txt

      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.19.2
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          name: Python Library Benchmark
          tool: "pytest"
          output-file-path: python/output.json
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/ringsaturn/tz-benchmark"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: false
          fail-on-alert: false
          gh-pages-branch: "gh-pages"
          benchmark-data-dir-path: "docs/"
          alert-comment-cc-users: "@ringsaturn"

      - name: Report
        run: |
          set +e
          echo "## Python ${{ matrix.python-version }}" >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          cat benchmark_result.txt >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}

      - run: ls -lah

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark_py_${{ steps.gen-benchmark-file-name.outputs.filename }}
          path: python/${{ steps.gen-benchmark-file-name.outputs.filename }}
          if-no-files-found: error

  bench-rust:
    defaults:
      run:
        working-directory: rust
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Setup benchmark file name
        id: gen-benchmark-file-name
        run: |
          echo "filename=tz_benchmark_rust.md" >> $GITHUB_OUTPUT

      - name: Run benchmark
        run: cargo bench | tee benchmark_result.txt

      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.19.2
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          name: Rust Library Benchmark
          tool: "cargo"
          output-file-path: rust/benchmark_result.txt
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/ringsaturn/tz-benchmark"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: false
          fail-on-alert: false
          gh-pages-branch: "gh-pages"
          benchmark-data-dir-path: "docs/"
          alert-comment-cc-users: "@ringsaturn"

      - name: Report
        run: |
          set +e
          echo "## Rust" >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          cat benchmark_result.txt >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}

      - run: ls -lah

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark_rust_${{ steps.gen-benchmark-file-name.outputs.filename }}
          path: rust/${{ steps.gen-benchmark-file-name.outputs.filename }}
          if-no-files-found: error

  summary:
    needs: [bench-go, bench-python, bench-rust]
    runs-on: ubuntu-latest
    steps:
      - name: Download a Build Artifact
        uses: actions/download-artifact@v4
        with:
          pattern: "benchmark_*"

      - name: Make Summary
        run: cat tz_benchmark_*.md > $GITHUB_STEP_SUMMARY
