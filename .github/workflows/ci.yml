name: ci

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: "1 1 * * 1"

permissions:
  contents: write
  deployments: write

jobs:
  bench-go:
    defaults:
      run:
        working-directory: go
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go/go.mod
          cache-dependency-path: |
            go/go.sum

      - name: Bench
        run: |
          go test -bench=. -benchmem ./... | tee benchmark_result.txt

      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.20.4
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          name: Go Library Benchmark
          tool: "go"
          output-file-path: go/benchmark_result.txt
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/ringsaturn/tz-benchmark"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: false
          fail-on-alert: false
          gh-pages-branch: "gh-pages"
          benchmark-data-dir-path: "docs/"
          alert-comment-cc-users: "@ringsaturn"

      - name: Setup benchmark file name
        id: gen-benchmark-file-name
        run: |
          echo "filename=tz_benchmark_go_${{ matrix.go-version }}.md" >> $GITHUB_OUTPUT

      - name: Report
        run: |
          set +e
          echo "## Go ${{ matrix.go-version }}" >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          cat benchmark_result.txt >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}

      - run: ls -lah

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark_go_${{ steps.gen-benchmark-file-name.outputs.filename }}
          path: go/${{ steps.gen-benchmark-file-name.outputs.filename }}
          if-no-files-found: error

  bench-python:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: python
    env:
      COLUMNS: 120

    steps:
      - uses: actions/checkout@v5

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true

      - run: uv sync

      - name: Setup benchmark file name
        id: gen-benchmark-file-name
        run: |
          echo "filename=tz_benchmark_py_${{ matrix.python-version }}.md" >> $GITHUB_OUTPUT

      - name: Bench Python
        run: |
          # ${{ steps.gen-benchmark-file-name.outputs.filename }}
          uv run pytest tz_test.py --benchmark-json output.json | tee benchmark_result.txt

      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.20.4
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          name: Python Library Benchmark
          tool: "pytest"
          output-file-path: python/output.json
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/ringsaturn/tz-benchmark"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: false
          fail-on-alert: false
          gh-pages-branch: "gh-pages"
          benchmark-data-dir-path: "docs/"
          alert-comment-cc-users: "@ringsaturn"

      - name: Report
        run: |
          set +e
          echo "## Python ${{ matrix.python-version }}" >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          cat benchmark_result.txt >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}

      - run: ls -lah

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark_py_${{ steps.gen-benchmark-file-name.outputs.filename }}
          path: python/${{ steps.gen-benchmark-file-name.outputs.filename }}
          if-no-files-found: error

  bench-rust:
    defaults:
      run:
        working-directory: rust
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5

      - uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Setup benchmark file name
        id: gen-benchmark-file-name
        run: |
          echo "filename=tz_benchmark_rust.md" >> $GITHUB_OUTPUT

      - name: Run benchmark
        run: cargo bench | tee benchmark_result.txt

      - name: Continuous Benchmark
        uses: benchmark-action/github-action-benchmark@v1.20.4
        if: ${{ github.ref == 'refs/heads/main' }}
        with:
          name: Rust Library Benchmark
          tool: "cargo"
          output-file-path: rust/benchmark_result.txt
          github-token: ${{ secrets.CI_TOKEN }}
          gh-repository: "github.com/ringsaturn/tz-benchmark"
          auto-push: true
          alert-threshold: "150%"
          comment-on-alert: false
          fail-on-alert: false
          gh-pages-branch: "gh-pages"
          benchmark-data-dir-path: "docs/"
          alert-comment-cc-users: "@ringsaturn"

      - name: Report
        run: |
          set +e
          echo "## Rust" >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          cat benchmark_result.txt >> ${{ steps.gen-benchmark-file-name.outputs.filename }}
          echo '```' >> ${{ steps.gen-benchmark-file-name.outputs.filename }}

      - run: ls -lah

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark_rust_${{ steps.gen-benchmark-file-name.outputs.filename }}
          path: rust/${{ steps.gen-benchmark-file-name.outputs.filename }}
          if-no-files-found: error

  summary:
    needs: [bench-go, bench-python, bench-rust]
    runs-on: ubuntu-latest
    steps:
      - name: Download a Build Artifact
        uses: actions/download-artifact@v5
        with:
          pattern: "benchmark_*"

      - run: find . -name "*.md" -exec cat {} \; > $GITHUB_STEP_SUMMARY
